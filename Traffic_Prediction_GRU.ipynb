{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "fedesoriano_traffic_prediction_dataset_path = kagglehub.dataset_download('fedesoriano/traffic-prediction-dataset')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "SGNqsC6A0se8"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_kg_hide-output": true,
        "_kg_hide-input": true,
        "execution": {
          "iopub.status.busy": "2021-09-02T07:03:48.060885Z",
          "iopub.execute_input": "2021-09-02T07:03:48.061189Z",
          "iopub.status.idle": "2021-09-02T07:03:48.086839Z",
          "shell.execute_reply.started": "2021-09-02T07:03:48.061116Z",
          "shell.execute_reply": "2021-09-02T07:03:48.086091Z"
        },
        "trusted": true,
        "id": "ABfcXSVN0sfD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# <p style=\"background-color:#627D78;font-family:newtimeroman;color:#D5CABD;font-size:150%;text-align:center;border-radius:20px 60px;\">Traffic Prediction</p>\n",
        "\n",
        "![Papercraft Voting Board Brainstorm Presentation.gif](attachment:1e7d0696-c04f-4bb4-94ae-b145bc90baf3.gif)\n",
        "\n",
        "\n",
        "Traffic is one of those annoying problems that affect many of us living in urban settings. One of the causes of traffic is the increase in urban populations. While the infrastructure is old and can only accommodate a limited population there is an influx of residents in search of livelihood and opportunities.\n",
        "\n",
        "Traffic congestions lead to an increased in the combustion of fuel. It further increases the carbon emissions causing air pollution. It also costs time and money. INRIX's, a transportation analytics and connected car services,  2020 report found that on average, Americans lost 99 hours a year due to congestion, costing them nearly 88 billion dollars in 2019, an average of 1,377 dollars per year. From 2017 to 2019 the average time lost by American drivers has increased by two hours as economic and urban growth continues.  [link](https://inrix.com/press-releases/2019-traffic-scorecard-us/)\n",
        "\n",
        "In this project, I will be exploring the dataset of four junctions and built a model to predict traffic on the same. This could potentially help in solving the traffic congestion problem by providing a better understanding of traffic patterns that will further help in building an infrastructure to eliminate the problem.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "   <a id='top'></a>\n",
        "<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n",
        "\n",
        "# <p style=\"background-color:#627D78;font-family:newtimeroman;color:#D5CABD;font-size:150%;text-align:center;border-radius:20px 60px;\">Table Of Contents</p>\n",
        "    \n",
        "* [1. IMPORTING LIBRARIES](#1)\n",
        "    \n",
        "* [2. LOADING DATA](#2)\n",
        "    \n",
        "* [3. DATA EXPLORATION](#3)\n",
        "    \n",
        "    * [3.1 FEATURE ENGINEERING](#3.1)\n",
        "    * [3.2 EXPLORATORY DATA ANALYSIS](#3.2)\n",
        "\n",
        "    \n",
        "* [4. DATA TRANSFORMATION AND PREPROCESSING](#4)\n",
        "    \n",
        "* [5. MODEL BUILDING](#5)\n",
        "    \n",
        "* [6. FITTING THE MODEL](#6)\n",
        "     \n",
        "* [7. INVERSING THE TRANSFORMATION OF DATA](#7)\n",
        "    \n",
        "* [8. END](#8)\n"
      ],
      "metadata": {
        "id": "fjARzxxJ0sfE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " <a id=\"1\"></a>\n",
        "# <p style=\"background-color:#627D78;font-family:newtimeroman;color:#D5CABD;font-size:150%;text-align:center;border-radius:20px 60px;\">Importing Libraries</p>"
      ],
      "metadata": {
        "id": "30lhuYco0sfH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import datetime\n",
        "import tensorflow\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow import keras\n",
        "from keras import callbacks\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, Flatten, Dense, LSTM, Dropout, GRU, Bidirectional\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "import math\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-02T07:03:48.09282Z",
          "iopub.execute_input": "2021-09-02T07:03:48.093051Z",
          "iopub.status.idle": "2021-09-02T07:03:53.339858Z",
          "shell.execute_reply.started": "2021-09-02T07:03:48.093028Z",
          "shell.execute_reply": "2021-09-02T07:03:53.3387Z"
        },
        "trusted": true,
        "id": "IQlGt3q20sfH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"2\"></a>\n",
        "# <p style=\"background-color:#627D78;font-family:newtimeroman;color:#D5CABD;font-size:150%;text-align:center;border-radius:20px 60px;\">Loading Data</p>"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-07-28T14:39:09.744085Z",
          "iopub.execute_input": "2021-07-28T14:39:09.744505Z",
          "iopub.status.idle": "2021-07-28T14:39:09.750683Z",
          "shell.execute_reply.started": "2021-07-28T14:39:09.744446Z",
          "shell.execute_reply": "2021-07-28T14:39:09.749326Z"
        },
        "id": "aqCmK99Y0sfI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Loading Data\n",
        "data = pd.read_csv(\"../input/traffic-prediction-dataset/traffic.csv\")\n",
        "data.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-02T07:03:53.344602Z",
          "iopub.execute_input": "2021-09-02T07:03:53.345005Z",
          "iopub.status.idle": "2021-09-02T07:03:53.466914Z",
          "shell.execute_reply.started": "2021-09-02T07:03:53.344968Z",
          "shell.execute_reply": "2021-09-02T07:03:53.466029Z"
        },
        "trusted": true,
        "id": "UEQeC96a0sfI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**About the data**\n",
        "\n",
        "This dataset is a collection of numbers of vehicles at four junctions at an hourly frequency.\n",
        "The CSV file provides four features:\n",
        "\n",
        "* DateTime\n",
        "* Junctions\n",
        "* Vehicles\n",
        "* ID\n",
        "\n",
        "The sensors on each of these junctions were collecting data at different times, hence the traffic data from different time periods. Some of the junctions have provided limited or sparse data."
      ],
      "metadata": {
        "id": "qAklccYm0sfJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"3\"></a>\n",
        "# <p style=\"background-color:#627D78;font-family:newtimeroman;color:#D5CABD;font-size:150%;text-align:center;border-radius:20px 60px;\">Data Exploration</p>\n",
        "* Pharsing dates\n",
        "* Ploting timeseris\n",
        "* Feature engineering for EDA"
      ],
      "metadata": {
        "id": "YUKuuzOQ0sfJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data[\"DateTime\"]= pd.to_datetime(data[\"DateTime\"])\n",
        "data = data.drop([\"ID\"], axis=1) #dropping IDs\n",
        "data.info()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-02T07:03:53.47113Z",
          "iopub.execute_input": "2021-09-02T07:03:53.473192Z",
          "iopub.status.idle": "2021-09-02T07:03:53.525237Z",
          "shell.execute_reply.started": "2021-09-02T07:03:53.473152Z",
          "shell.execute_reply": "2021-09-02T07:03:53.524303Z"
        },
        "trusted": true,
        "id": "HEPHR68s0sfJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#df to be used for EDA\n",
        "df=data.copy()\n",
        "#Let's plot the Timeseries\n",
        "colors = [ \"#FFD4DB\",\"#BBE7FE\",\"#D3B5E5\",\"#dfe2b6\"]\n",
        "plt.figure(figsize=(20,4),facecolor=\"#627D78\")\n",
        "Time_series=sns.lineplot(x=df['DateTime'],y=\"Vehicles\",data=df, hue=\"Junction\", palette=colors)\n",
        "Time_series.set_title(\"Traffic On Junctions Over Years\")\n",
        "Time_series.set_ylabel(\"Number of Vehicles\")\n",
        "Time_series.set_xlabel(\"Date\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-02T07:03:53.529128Z",
          "iopub.execute_input": "2021-09-02T07:03:53.531136Z",
          "iopub.status.idle": "2021-09-02T07:03:56.342133Z",
          "shell.execute_reply.started": "2021-09-02T07:03:53.531098Z",
          "shell.execute_reply": "2021-09-02T07:03:56.341282Z"
        },
        "trusted": true,
        "id": "yOPXMDPm0sfJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Noticeable information in the above plot:**\n",
        "\n",
        "* It can be seen here that the first junction is visibly having an upward trend.\n",
        "* The data for the fourth junction is sparse starting only after 2017\n",
        "* Seasonality is not evident from the above plot, So we must explore datetime composition to figure out more about it."
      ],
      "metadata": {
        "id": "0JbukpBv0sfK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"3.1\"></a>\n",
        "# <p style=\"background-color:#627D78;font-family:newtimeroman;color:#D5CABD;font-size:150%;text-align:center;border-radius:20px 60px;\">Feature Engineering</p>\n",
        "\n",
        "At this step, I am creating a few new features out of DateTime.\n",
        "Namely:\n",
        "* Year\n",
        "* Month\n",
        "* Date in the given month\n",
        "* Days of week\n",
        "* Hour"
      ],
      "metadata": {
        "id": "qYYl6JRw0sfK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Exploring more features\n",
        "df[\"Year\"]= df['DateTime'].dt.year\n",
        "df[\"Month\"]= df['DateTime'].dt.month\n",
        "df[\"Date_no\"]= df['DateTime'].dt.day\n",
        "df[\"Hour\"]= df['DateTime'].dt.hour\n",
        "df[\"Day\"]= df.DateTime.dt.strftime(\"%A\")\n",
        "df.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-02T07:03:56.343173Z",
          "iopub.execute_input": "2021-09-02T07:03:56.34352Z",
          "iopub.status.idle": "2021-09-02T07:03:56.683722Z",
          "shell.execute_reply.started": "2021-09-02T07:03:56.343482Z",
          "shell.execute_reply": "2021-09-02T07:03:56.68262Z"
        },
        "trusted": true,
        "id": "TcN1DKl70sfK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"3.2\"></a>\n",
        "# <p style=\"background-color:#627D78;font-family:newtimeroman;color:#D5CABD;font-size:150%;text-align:center;border-radius:20px 60px;\">Exploratory Data Analysis</p>\n",
        "\n",
        "Plotting the newly created features"
      ],
      "metadata": {
        "id": "8n7zYKX40sfK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Let's plot the Timeseries\n",
        "new_features = [ \"Year\",\"Month\", \"Date_no\", \"Hour\", \"Day\"]\n",
        "\n",
        "for i in new_features:\n",
        "    plt.figure(figsize=(10,2),facecolor=\"#627D78\")\n",
        "    ax=sns.lineplot(x=df[i],y=\"Vehicles\",data=df, hue=\"Junction\", palette=colors )\n",
        "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-02T07:03:56.685205Z",
          "iopub.execute_input": "2021-09-02T07:03:56.685614Z",
          "iopub.status.idle": "2021-09-02T07:04:08.331875Z",
          "shell.execute_reply.started": "2021-09-02T07:03:56.685579Z",
          "shell.execute_reply": "2021-09-02T07:04:08.330935Z"
        },
        "trusted": true,
        "id": "flLVSdnw0sfL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**From the above plot following things can be concluded:**\n",
        "\n",
        "\n",
        "* Yearly, there has been an upward trend for all junctions except for the fourth junction. As we already established above that the fourth junction has limited data and that don't span over a year.  \n",
        "\n",
        "* We can see that there is an influx in the first and second junctions around June. I presume this may be due to summer break and activities around the same.\n",
        "\n",
        "* Monthly, throughout all the dates there is a good consistency in data.\n",
        "\n",
        "* For a day, we can see that are peaks during morning and evening times and a decline during night hours. This is as per expectation.\n",
        "\n",
        "* For weekly patterns, Sundays enjoy smoother traffic as there are lesser vehicles on roads. Whereas Monday to Friday the traffic is steady.\n"
      ],
      "metadata": {
        "id": "x1GEqnhx0sfL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12,5),facecolor=\"#627D78\")\n",
        "count = sns.countplot(data=df, x =df[\"Year\"], hue=\"Junction\", palette=colors)\n",
        "count.set_title(\"Count Of Traffic On Junctions Over Years\")\n",
        "count.set_ylabel(\"Number of Vehicles\")\n",
        "count.set_xlabel(\"Date\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-02T07:04:08.333221Z",
          "iopub.execute_input": "2021-09-02T07:04:08.333577Z",
          "iopub.status.idle": "2021-09-02T07:04:08.552589Z",
          "shell.execute_reply.started": "2021-09-02T07:04:08.333542Z",
          "shell.execute_reply": "2021-09-02T07:04:08.551679Z"
        },
        "trusted": true,
        "id": "pUmhg_w80sfL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The count plot shows that there is an increase in the number of vehicles between 2015 and 2016. However, it is inconclusive to say the same about 2017 as we have limited data for 2017 ie till the 7th month."
      ],
      "metadata": {
        "id": "qQl41hog0sfM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corrmat = df.corr()\n",
        "plt.subplots(figsize=(10,10),facecolor=\"#627D78\")\n",
        "sns.heatmap(corrmat,cmap= \"Pastel2\",annot=True,square=True, )"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-02T07:04:08.555295Z",
          "iopub.execute_input": "2021-09-02T07:04:08.555719Z",
          "iopub.status.idle": "2021-09-02T07:04:08.979428Z",
          "shell.execute_reply.started": "2021-09-02T07:04:08.555678Z",
          "shell.execute_reply": "2021-09-02T07:04:08.978649Z"
        },
        "trusted": true,
        "id": "XKevx7kc0sfM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The highest correlation is certainly with the preexisting feature.\n",
        "\n",
        "I will conclude my EDA with a pair plot. It's an interesting overall representation of any data."
      ],
      "metadata": {
        "id": "QhH10xWV0sfM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.pairplot(data=df, hue= \"Junction\",palette=colors)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-02T07:04:08.981042Z",
          "iopub.execute_input": "2021-09-02T07:04:08.981289Z",
          "iopub.status.idle": "2021-09-02T07:05:22.387186Z",
          "shell.execute_reply.started": "2021-09-02T07:04:08.981264Z",
          "shell.execute_reply": "2021-09-02T07:05:22.386265Z"
        },
        "trusted": true,
        "id": "HFPmmP1e0sfN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Conclusions that I have come to draw after this EDA**\n",
        "\n",
        "* The span of data from all four junctions is not the same. Data provided for the fourth junction is limited to only 2017.\n",
        "* The yearly trend for Junctions one, two and three have diffrent slopes.\n",
        "* Junction number one has a more strong weekly seasonality in comparison to the other junctions.\n",
        "\n",
        "For the above-postulated reasons, I think that junctions must be transformed as per their individual needs.\n",
        "\n"
      ],
      "metadata": {
        "id": "Jy18MaBN0sfN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"4\"></a>\n",
        "# <p style=\"background-color:#627D78;font-family:newtimeroman;color:#D5CABD;font-size:150%;text-align:center;border-radius:20px 60px;\">Data Transformation And Preprocessing</p>\n",
        "\n",
        "**In this step I will be following the subsequent order:**\n",
        "\n",
        "* Creating different frames for each Junction and plotting them\n",
        "* Transforming the series and plotting them\n",
        "* Performing the Augmented Dickey-Fuller test to check the seasonality of transformed series\n",
        "* Creating test and train sets\n"
      ],
      "metadata": {
        "id": "9Ib_84bN0sfN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Pivoting data fron junction\n",
        "df_J = data.pivot(columns=\"Junction\", index=\"DateTime\")\n",
        "df_J.describe()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-02T07:05:22.388561Z",
          "iopub.execute_input": "2021-09-02T07:05:22.388908Z",
          "iopub.status.idle": "2021-09-02T07:05:22.433584Z",
          "shell.execute_reply.started": "2021-09-02T07:05:22.388873Z",
          "shell.execute_reply": "2021-09-02T07:05:22.432676Z"
        },
        "trusted": true,
        "id": "wxmsSZfU0sfO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating new sets\n",
        "df_1 = df_J[[('Vehicles', 1)]]\n",
        "df_2 = df_J[[('Vehicles', 2)]]\n",
        "df_3 = df_J[[('Vehicles', 3)]]\n",
        "df_4 = df_J[[('Vehicles', 4)]]\n",
        "df_4 = df_4.dropna() #Junction 4 has limited data only for a few months\n",
        "\n",
        "#Dropping level one in dfs's index as it is a multi index data frame\n",
        "list_dfs = [df_1, df_2, df_3, df_4]\n",
        "for i in list_dfs:\n",
        "    i.columns= i.columns.droplevel(level=1)\n",
        "\n",
        "#Function to plot comparitive plots of dataframes\n",
        "def Sub_Plots4(df_1, df_2,df_3,df_4,title):\n",
        "    fig, axes = plt.subplots(4, 1, figsize=(15, 8),facecolor=\"#627D78\", sharey=True)\n",
        "    fig.suptitle(title)\n",
        "    #J1\n",
        "    pl_1=sns.lineplot(ax=axes[0],data=df_1,color=colors[0])\n",
        "    #pl_1=plt.ylabel()\n",
        "    axes[0].set(ylabel =\"Junction 1\")\n",
        "    #J2\n",
        "    pl_2=sns.lineplot(ax=axes[1],data=df_2,color=colors[1])\n",
        "    axes[1].set(ylabel =\"Junction 2\")\n",
        "    #J3\n",
        "    pl_3=sns.lineplot(ax=axes[2],data=df_3,color=colors[2])\n",
        "    axes[2].set(ylabel =\"Junction 3\")\n",
        "    #J4\n",
        "    pl_4=sns.lineplot(ax=axes[3],data=df_4,color=colors[3])\n",
        "    axes[3].set(ylabel =\"Junction 4\")\n",
        "\n",
        "\n",
        "#Plotting the dataframe to check for stationarity\n",
        "Sub_Plots4(df_1.Vehicles, df_2.Vehicles,df_3.Vehicles,df_4.Vehicles,\"Dataframes Before Transformation\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-02T07:05:22.434951Z",
          "iopub.execute_input": "2021-09-02T07:05:22.435289Z",
          "iopub.status.idle": "2021-09-02T07:05:25.474942Z",
          "shell.execute_reply.started": "2021-09-02T07:05:22.435255Z",
          "shell.execute_reply": "2021-09-02T07:05:25.473962Z"
        },
        "trusted": true,
        "id": "37_Nd8dG0sfO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A time series is stationary if it does not have a trend or seasonality. However, in the EDA, we saw a weekly seasonality and an upwards trend over the years. In the above plot, it is again established that Junctions one and two have an upward trend. If we limit the span we will be able to further see the weekly seasonality. I will be spairing that step at this point and moving on with the respective transforms on datasets.\n",
        "\n",
        "**Steps for Transforming:**\n",
        "* Normalizing\n",
        "* Differencing"
      ],
      "metadata": {
        "id": "4cy0aXOR0sfO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize Function\n",
        "def Normalize(df,col):\n",
        "    average = df[col].mean()\n",
        "    stdev = df[col].std()\n",
        "    df_normalized = (df[col] - average) / stdev\n",
        "    df_normalized = df_normalized.to_frame()\n",
        "    return df_normalized, average, stdev\n",
        "\n",
        "# Differencing Function\n",
        "def Difference(df,col, interval):\n",
        "    diff = []\n",
        "    for i in range(interval, len(df)):\n",
        "        value = df[col][i] - df[col][i - interval]\n",
        "        diff.append(value)\n",
        "    return diff"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-02T07:05:25.47641Z",
          "iopub.execute_input": "2021-09-02T07:05:25.476752Z",
          "iopub.status.idle": "2021-09-02T07:05:25.484141Z",
          "shell.execute_reply.started": "2021-09-02T07:05:25.476717Z",
          "shell.execute_reply": "2021-09-02T07:05:25.483402Z"
        },
        "trusted": true,
        "id": "qLrYI8dI0sfO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In accordance with the above observations, Differencing to eliminate the seasonality should be performed as follows:\n",
        "* For Junction one, I will be taking a difference of weekly values.\n",
        "* For junction two, The difference of consecutive days is a better choice\n",
        "* For Junctions three and four, the difference of the hourly values will serve the purpose."
      ],
      "metadata": {
        "id": "weXUb2IZ0sfP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Normalizing and Differencing to make the series stationary\n",
        "df_N1, av_J1, std_J1 = Normalize(df_1, \"Vehicles\")\n",
        "Diff_1 = Difference(df_N1, col=\"Vehicles\", interval=(24*7)) #taking a week's diffrence\n",
        "df_N1 = df_N1[24*7:]\n",
        "df_N1.columns = [\"Norm\"]\n",
        "df_N1[\"Diff\"]= Diff_1\n",
        "\n",
        "df_N2, av_J2, std_J2 = Normalize(df_2, \"Vehicles\")\n",
        "Diff_2 = Difference(df_N2, col=\"Vehicles\", interval=(24)) #taking a day's diffrence\n",
        "df_N2 = df_N2[24:]\n",
        "df_N2.columns = [\"Norm\"]\n",
        "df_N2[\"Diff\"]= Diff_2\n",
        "\n",
        "df_N3, av_J3, std_J3 = Normalize(df_3, \"Vehicles\")\n",
        "Diff_3 = Difference(df_N3, col=\"Vehicles\", interval=1) #taking an hour's diffrence\n",
        "df_N3 = df_N3[1:]\n",
        "df_N3.columns = [\"Norm\"]\n",
        "df_N3[\"Diff\"]= Diff_3\n",
        "\n",
        "df_N4, av_J4, std_J4 = Normalize(df_4, \"Vehicles\")\n",
        "Diff_4 = Difference(df_N4, col=\"Vehicles\", interval=1) #taking an hour's diffrence\n",
        "df_N4 = df_N4[1:]\n",
        "df_N4.columns = [\"Norm\"]\n",
        "df_N4[\"Diff\"]= Diff_4"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-02T07:05:25.485449Z",
          "iopub.execute_input": "2021-09-02T07:05:25.485799Z",
          "iopub.status.idle": "2021-09-02T07:05:26.118142Z",
          "shell.execute_reply.started": "2021-09-02T07:05:25.485763Z",
          "shell.execute_reply": "2021-09-02T07:05:26.117307Z"
        },
        "trusted": true,
        "id": "w09LYjS00sfP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Plots of Transformed Dataframe**"
      ],
      "metadata": {
        "id": "B5-ZhhDy0sfP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Sub_Plots4(df_N1.Diff, df_N2.Diff,df_N3.Diff,df_N4.Diff,\"Dataframes After Transformation\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-02T07:05:26.119385Z",
          "iopub.execute_input": "2021-09-02T07:05:26.119763Z",
          "iopub.status.idle": "2021-09-02T07:05:29.259865Z",
          "shell.execute_reply.started": "2021-09-02T07:05:26.119727Z",
          "shell.execute_reply": "2021-09-02T07:05:29.258879Z"
        },
        "trusted": true,
        "id": "Wt6hjH4R0sfQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The plots above seem linear. To ensure they are Stationary I will be performing an Augmented Dickey-Fuller test."
      ],
      "metadata": {
        "id": "Li-7518m0sfQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Stationary Check for the time series Augmented Dickey Fuller test\n",
        "def Stationary_check(df):\n",
        "    check = adfuller(df.dropna())\n",
        "    print(f\"ADF Statistic: {check[0]}\")\n",
        "    print(f\"p-value: {check[1]}\")\n",
        "    print(\"Critical Values:\")\n",
        "    for key, value in check[4].items():\n",
        "        print('\\t%s: %.3f' % (key, value))\n",
        "    if check[0] > check[4][\"1%\"]:\n",
        "        print(\"Time Series is Non-Stationary\")\n",
        "    else:\n",
        "        print(\"Time Series is Stationary\")\n",
        "\n",
        "\n",
        "#Checking if the series is stationary\n",
        "\n",
        "List_df_ND = [ df_N1[\"Diff\"], df_N2[\"Diff\"], df_N3[\"Diff\"], df_N4[\"Diff\"]]\n",
        "print(\"Checking the transformed series for stationarity:\")\n",
        "for i in List_df_ND:\n",
        "    print(\"\\n\")\n",
        "    Stationary_check(i)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-02T07:05:29.261264Z",
          "iopub.execute_input": "2021-09-02T07:05:29.261629Z",
          "iopub.status.idle": "2021-09-02T07:05:33.39356Z",
          "shell.execute_reply.started": "2021-09-02T07:05:29.261595Z",
          "shell.execute_reply": "2021-09-02T07:05:33.391163Z"
        },
        "trusted": true,
        "id": "IxLr-QbK0sfR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Now that the data is stationary,  preprocessing the data for the neural net by:**\n",
        "\n",
        "* Splitting the test train sets\n",
        "* Assigning X as features and y as target\n",
        "* Reshaping data for neural net"
      ],
      "metadata": {
        "id": "qoef69NI0sfS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Differencing created some NA values as we took a weeks data into consideration while difrencing\n",
        "df_J1 = df_N1[\"Diff\"].dropna()\n",
        "df_J1 = df_J1.to_frame()\n",
        "\n",
        "df_J2 = df_N2[\"Diff\"].dropna()\n",
        "df_J2 = df_J2.to_frame()\n",
        "\n",
        "df_J3 = df_N3[\"Diff\"].dropna()\n",
        "df_J3 = df_J3.to_frame()\n",
        "\n",
        "df_J4 = df_N4[\"Diff\"].dropna()\n",
        "df_J4 = df_J4.to_frame()\n",
        "\n",
        "#Splitting the dataset\n",
        "def Split_data(df):\n",
        "    training_size = int(len(df)*0.90)\n",
        "    data_len = len(df)\n",
        "    train, test = df[0:training_size],df[training_size:data_len]\n",
        "    train, test = train.values.reshape(-1, 1), test.values.reshape(-1, 1)\n",
        "    return train, test\n",
        "#Splitting the training and test datasets\n",
        "J1_train, J1_test = Split_data(df_J1)\n",
        "J2_train, J2_test = Split_data(df_J2)\n",
        "J3_train, J3_test = Split_data(df_J3)\n",
        "J4_train, J4_test = Split_data(df_J4)\n",
        "\n",
        "#Target and Feature\n",
        "def TnF(df):\n",
        "    end_len = len(df)\n",
        "    X = []\n",
        "    y = []\n",
        "    steps = 32\n",
        "    for i in range(steps, end_len):\n",
        "        X.append(df[i - steps:i, 0])\n",
        "        y.append(df[i, 0])\n",
        "    X, y = np.array(X), np.array(y)\n",
        "    return X ,y\n",
        "\n",
        "#fixing the shape of X_test and X_train\n",
        "def FeatureFixShape(train, test):\n",
        "    train = np.reshape(train, (train.shape[0], train.shape[1], 1))\n",
        "    test = np.reshape(test, (test.shape[0],test.shape[1],1))\n",
        "    return train, test\n",
        "\n",
        "#Assigning features and target\n",
        "X_trainJ1, y_trainJ1 = TnF(J1_train)\n",
        "X_testJ1, y_testJ1 = TnF(J1_test)\n",
        "X_trainJ1, X_testJ1 = FeatureFixShape(X_trainJ1, X_testJ1)\n",
        "\n",
        "X_trainJ2, y_trainJ2 = TnF(J2_train)\n",
        "X_testJ2, y_testJ2 = TnF(J2_test)\n",
        "X_trainJ2, X_testJ2 = FeatureFixShape(X_trainJ2, X_testJ2)\n",
        "\n",
        "X_trainJ3, y_trainJ3 = TnF(J3_train)\n",
        "X_testJ3, y_testJ3 = TnF(J3_test)\n",
        "X_trainJ3, X_testJ3 = FeatureFixShape(X_trainJ3, X_testJ3)\n",
        "\n",
        "X_trainJ4, y_trainJ4 = TnF(J4_train)\n",
        "X_testJ4, y_testJ4 = TnF(J4_test)\n",
        "X_trainJ4, X_testJ4 = FeatureFixShape(X_trainJ4, X_testJ4)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-02T07:05:33.394861Z",
          "iopub.execute_input": "2021-09-02T07:05:33.395171Z",
          "iopub.status.idle": "2021-09-02T07:05:33.549565Z",
          "shell.execute_reply.started": "2021-09-02T07:05:33.395145Z",
          "shell.execute_reply": "2021-09-02T07:05:33.548673Z"
        },
        "trusted": true,
        "id": "jk7B3BM70sfT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"5\"></a>\n",
        "# <p style=\"background-color:#627D78;font-family:newtimeroman;color:#D5CABD;font-size:150%;text-align:center;border-radius:20px 60px;\">Model Building</p>\n",
        "\n",
        "For this project, I have settled to use Gated Recurrent Unit (GRU). In this section, I am creating a function for the neural net to call on and fit the data frames for all four junctions."
      ],
      "metadata": {
        "id": "aS0r4qOI0sfU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Model for the prediction\n",
        "def GRU_model(X_Train, y_Train, X_Test):\n",
        "    early_stopping = callbacks.EarlyStopping(min_delta=0.001,patience=10, restore_best_weights=True)\n",
        "    #callback delta 0.01 may interrupt the learning, could eliminate this step, but meh!\n",
        "\n",
        "    #The GRU model\n",
        "    model = Sequential()\n",
        "    model.add(GRU(units=150, return_sequences=True, input_shape=(X_Train.shape[1],1), activation='tanh'))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(GRU(units=150, return_sequences=True, input_shape=(X_Train.shape[1],1), activation='tanh'))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(GRU(units=50, return_sequences=True, input_shape=(X_Train.shape[1],1), activation='tanh'))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(GRU(units=50, return_sequences=True, input_shape=(X_Train.shape[1],1), activation='tanh'))\n",
        "    model.add(Dropout(0.2))\n",
        "    #model.add(GRU(units=50, return_sequences=True,  input_shape=(X_Train.shape[1],1),activation='tanh'))\n",
        "    #model.add(Dropout(0.2))\n",
        "    model.add(GRU(units=50, input_shape=(X_Train.shape[1],1), activation='tanh'))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(units=1))\n",
        "    #Compiling the model\n",
        "    model.compile(optimizer=SGD(decay=1e-7, momentum=0.9),loss='mean_squared_error')\n",
        "    model.fit(X_Train,y_Train, epochs=50, batch_size=150,callbacks=[early_stopping])\n",
        "    pred_GRU= model.predict(X_Test)\n",
        "    return pred_GRU\n",
        "\n",
        "#To calculate the root mean squred error in predictions\n",
        "def RMSE_Value(test,predicted):\n",
        "    rmse = math.sqrt(mean_squared_error(test, predicted))\n",
        "    print(\"The root mean squared error is {}.\".format(rmse))\n",
        "    return rmse\n",
        "\n",
        "#To plot the comparitive plot of targets and predictions\n",
        "def PredictionsPlot(test,predicted,m):\n",
        "    plt.figure(figsize=(12,5),facecolor=\"#627D78\")\n",
        "    plt.plot(test, color=colors[m],label=\"True Value\",alpha=0.5 )\n",
        "    plt.plot(predicted, color=\"#627D78\",label=\"Predicted Values\")\n",
        "    plt.title(\"GRU Traffic Prediction Vs True values\")\n",
        "    plt.xlabel(\"DateTime\")\n",
        "    plt.ylabel(\"Number of Vehicles\")\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-02T07:05:33.55076Z",
          "iopub.execute_input": "2021-09-02T07:05:33.551085Z",
          "iopub.status.idle": "2021-09-02T07:05:33.565922Z",
          "shell.execute_reply.started": "2021-09-02T07:05:33.551058Z",
          "shell.execute_reply": "2021-09-02T07:05:33.565112Z"
        },
        "trusted": true,
        "id": "Z_-C0-Ww0sfV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"6\"></a>\n",
        "# <p style=\"background-color:#627D78;font-family:newtimeroman;color:#D5CABD;font-size:150%;text-align:center;border-radius:20px 60px;\">Fitting The Model</p>\n",
        "\n",
        "Now, I will be fitting the transformed training sets of four junctions to the model created and compare them to the transformed test sets."
      ],
      "metadata": {
        "id": "hsCQXJnr0sfX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Fitting the first junction and plotting the predictions and testset**"
      ],
      "metadata": {
        "id": "ZHaLvd0X0sfY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Predictions For First Junction\n",
        "PredJ1 = GRU_model(X_trainJ1,y_trainJ1,X_testJ1)"
      ],
      "metadata": {
        "_kg_hide-output": true,
        "execution": {
          "iopub.status.busy": "2021-09-02T07:05:33.567207Z",
          "iopub.execute_input": "2021-09-02T07:05:33.567612Z",
          "iopub.status.idle": "2021-09-02T07:07:13.303041Z",
          "shell.execute_reply.started": "2021-09-02T07:05:33.567575Z",
          "shell.execute_reply": "2021-09-02T07:07:13.302152Z"
        },
        "trusted": true,
        "id": "8u6Z249L0sfZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Results for J1\n",
        "RMSE_J1=RMSE_Value(y_testJ1,PredJ1)\n",
        "PredictionsPlot(y_testJ1,PredJ1,0)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-02T07:07:13.304469Z",
          "iopub.execute_input": "2021-09-02T07:07:13.304815Z",
          "iopub.status.idle": "2021-09-02T07:07:13.478537Z",
          "shell.execute_reply.started": "2021-09-02T07:07:13.304779Z",
          "shell.execute_reply": "2021-09-02T07:07:13.477602Z"
        },
        "trusted": true,
        "id": "-ZRSIDtb0sfZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Fitting the second junction and plotting the predictions and testset**"
      ],
      "metadata": {
        "id": "zuvQR3R20sfZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Predictions For Second Junction\n",
        "PredJ2 = GRU_model(X_trainJ2,y_trainJ2,X_testJ2)"
      ],
      "metadata": {
        "_kg_hide-output": true,
        "execution": {
          "iopub.status.busy": "2021-09-02T07:07:13.479877Z",
          "iopub.execute_input": "2021-09-02T07:07:13.480208Z",
          "iopub.status.idle": "2021-09-02T07:08:47.019908Z",
          "shell.execute_reply.started": "2021-09-02T07:07:13.480171Z",
          "shell.execute_reply": "2021-09-02T07:08:47.018864Z"
        },
        "trusted": true,
        "id": "04GqJ-9I0sfZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Results for J2\n",
        "RMSE_J2=RMSE_Value(y_testJ2,PredJ2)\n",
        "PredictionsPlot(y_testJ2,PredJ2,1)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-02T07:08:47.021282Z",
          "iopub.execute_input": "2021-09-02T07:08:47.021629Z",
          "iopub.status.idle": "2021-09-02T07:08:47.202989Z",
          "shell.execute_reply.started": "2021-09-02T07:08:47.021594Z",
          "shell.execute_reply": "2021-09-02T07:08:47.202064Z"
        },
        "trusted": true,
        "id": "hS6JzrTG0sfZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Fitting the third junction and plotting the predictions and testset**"
      ],
      "metadata": {
        "id": "Xx7Q14Ec0sfa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Predictions For Third Junction\n",
        "PredJ3 = GRU_model(X_trainJ3,y_trainJ3,X_testJ3)"
      ],
      "metadata": {
        "_kg_hide-output": true,
        "execution": {
          "iopub.status.busy": "2021-09-02T07:08:47.204447Z",
          "iopub.execute_input": "2021-09-02T07:08:47.204763Z",
          "iopub.status.idle": "2021-09-02T07:10:20.441705Z",
          "shell.execute_reply.started": "2021-09-02T07:08:47.204731Z",
          "shell.execute_reply": "2021-09-02T07:10:20.44084Z"
        },
        "trusted": true,
        "id": "aXTjTWVU0sfa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Results for J3\n",
        "RMSE_J3=RMSE_Value(y_testJ3,PredJ3)\n",
        "PredictionsPlot(y_testJ3,PredJ3,2)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-02T07:10:20.445335Z",
          "iopub.execute_input": "2021-09-02T07:10:20.445631Z",
          "iopub.status.idle": "2021-09-02T07:10:20.60957Z",
          "shell.execute_reply.started": "2021-09-02T07:10:20.445604Z",
          "shell.execute_reply": "2021-09-02T07:10:20.608641Z"
        },
        "trusted": true,
        "id": "Qwjg1NNh0sfa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Fitting the fourth junction and plotting the predictions and testset**"
      ],
      "metadata": {
        "id": "A2So8QGo0sfa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Predictions For Forth Junction\n",
        "PredJ4 = GRU_model(X_trainJ4,y_trainJ4,X_testJ4)"
      ],
      "metadata": {
        "_kg_hide-output": true,
        "execution": {
          "iopub.status.busy": "2021-09-02T07:10:20.611181Z",
          "iopub.execute_input": "2021-09-02T07:10:20.611536Z",
          "iopub.status.idle": "2021-09-02T07:10:53.875978Z",
          "shell.execute_reply.started": "2021-09-02T07:10:20.6115Z",
          "shell.execute_reply": "2021-09-02T07:10:53.875072Z"
        },
        "trusted": true,
        "id": "_N3C-srK0sfa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Results for J4\n",
        "RMSE_J4=RMSE_Value(y_testJ4,PredJ4)\n",
        "PredictionsPlot(y_testJ4,PredJ4,3)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-02T07:10:53.877414Z",
          "iopub.execute_input": "2021-09-02T07:10:53.877744Z",
          "iopub.status.idle": "2021-09-02T07:10:54.066775Z",
          "shell.execute_reply.started": "2021-09-02T07:10:53.877709Z",
          "shell.execute_reply": "2021-09-02T07:10:54.065996Z"
        },
        "trusted": true,
        "id": "2Hrjagvs0sfa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The results of the model**"
      ],
      "metadata": {
        "id": "RtJFwHHj0sfb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Initialise data of lists for error values of four junctions.\n",
        "Junctions = [\"Junction1\", \"Junction2\", \"Junction3\", \"Junction4\"]\n",
        "RMSE = [RMSE_J1, RMSE_J2, RMSE_J3, RMSE_J4]\n",
        "list_of_tuples = list(zip(Junctions, RMSE))\n",
        "# Creates pandas DataFrame.\n",
        "Results = pd.DataFrame(list_of_tuples, columns=[\"Junction\", \"RMSE\"])\n",
        "Results.style.background_gradient(cmap=\"Pastel1\")\n"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.status.busy": "2021-09-02T07:10:54.068014Z",
          "iopub.execute_input": "2021-09-02T07:10:54.068365Z",
          "iopub.status.idle": "2021-09-02T07:10:54.106741Z",
          "shell.execute_reply.started": "2021-09-02T07:10:54.068329Z",
          "shell.execute_reply": "2021-09-02T07:10:54.105811Z"
        },
        "trusted": true,
        "id": "YvaUgSRS0sfb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The Root Mean Square Error is quite a subjective marker for evaluating the performance.\n",
        "Thus, in this project, I am including the outcome plots as well.**"
      ],
      "metadata": {
        "id": "VY08Z9vm0sfb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"7\"></a>\n",
        "# <p style=\"background-color:#627D78;font-family:newtimeroman;color:#D5CABD;font-size:150%;text-align:center;border-radius:20px 60px;\">Inversing The Transformation Of Data</p>\n",
        "\n",
        "In this section, I will be inversing transforms that I applied to the datasets to remove the seasonality and trends.\n",
        "Performing this step will make the predictions get back on the accurate scale.\n",
        "\n",
        "Resource to the inversion process [Link](https://machinelearningmastery.com/remove-trends-seasonality-difference-transform-python/)"
      ],
      "metadata": {
        "id": "ddZkkT7N0sfb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Functions to inverse transforms and Plot comparitive plots\n",
        "# invert differenced forecast\n",
        "def inverse_difference(last_ob, value):\n",
        "    inversed = value + last_ob\n",
        "    return inversed\n",
        "#Plotting the comparison\n",
        "def Sub_Plots2(df_1, df_2,title,m):\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(18,4), sharey=True,facecolor=\"#627D78\")\n",
        "    fig.suptitle(title)\n",
        "\n",
        "    pl_1=sns.lineplot(ax=axes[0],data=df_1,color=colors[m])\n",
        "    axes[0].set(ylabel =\"Prediction\")\n",
        "\n",
        "    pl_2=sns.lineplot(ax=axes[1],data=df_2[\"Vehicles\"],color=\"#627D78\")\n",
        "    axes[1].set(ylabel =\"Orignal\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-02T07:10:54.108088Z",
          "iopub.execute_input": "2021-09-02T07:10:54.108464Z",
          "iopub.status.idle": "2021-09-02T07:10:54.115345Z",
          "shell.execute_reply.started": "2021-09-02T07:10:54.108427Z",
          "shell.execute_reply": "2021-09-02T07:10:54.114381Z"
        },
        "trusted": true,
        "id": "s1WN-m3b0sfb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**the inverse transform on the first junction**"
      ],
      "metadata": {
        "id": "uUE23cdz0sfb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# invert the differenced forecast for Junction 1\n",
        "recover1 = df_N1.Norm[-1412:-1].to_frame()\n",
        "recover1[\"Pred\"]= PredJ1\n",
        "Transform_reverssed_J1 = inverse_difference(recover1.Norm, recover1.Pred).to_frame()\n",
        "Transform_reverssed_J1.columns = [\"Pred_Normed\"]\n",
        "#Invert the normalizeation J1\n",
        "Final_J1_Pred = (Transform_reverssed_J1.values* std_J1) + av_J1\n",
        "Transform_reverssed_J1[\"Pred_Final\"] =Final_J1_Pred\n",
        "#Plotting the Predictions with orignals\n",
        "Sub_Plots2(Transform_reverssed_J1[\"Pred_Final\"], df_1[-1412:-1],\"Pridictions And Orignals For Junction 1\", 0)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-02T07:10:54.116704Z",
          "iopub.execute_input": "2021-09-02T07:10:54.117153Z",
          "iopub.status.idle": "2021-09-02T07:10:54.661331Z",
          "shell.execute_reply.started": "2021-09-02T07:10:54.117117Z",
          "shell.execute_reply": "2021-09-02T07:10:54.660513Z"
        },
        "trusted": true,
        "id": "D6HOizud0sfc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**the inverse transform on the second junction**"
      ],
      "metadata": {
        "id": "SqHgNmDN0sfc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Invert the differenced J2\n",
        "recover2 = df_N2.Norm[-1426:-1].to_frame() #len as per the diff\n",
        "recover2[\"Pred\"]= PredJ2\n",
        "Transform_reverssed_J2 = inverse_difference(recover2.Norm, recover2.Pred).to_frame()\n",
        "Transform_reverssed_J2.columns = [\"Pred_Normed\"]\n",
        "Final_J2_Pred = (Transform_reverssed_J2.values* std_J2) + av_J2\n",
        "Transform_reverssed_J2[\"Pred_Final\"] =Final_J2_Pred\n",
        "#Plotting the Predictions with orignals\n",
        "Sub_Plots2(Transform_reverssed_J2[\"Pred_Final\"], df_2[-1426:-1],\"Pridictions And Orignals For Junction 2\", 1)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-02T07:10:54.662522Z",
          "iopub.execute_input": "2021-09-02T07:10:54.662965Z",
          "iopub.status.idle": "2021-09-02T07:10:55.626748Z",
          "shell.execute_reply.started": "2021-09-02T07:10:54.66293Z",
          "shell.execute_reply": "2021-09-02T07:10:55.625922Z"
        },
        "trusted": true,
        "id": "GIhRCCnk0sfc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The inverse transform on the third junction**"
      ],
      "metadata": {
        "id": "WRiL7I0j0sfc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Invert the differenced J3\n",
        "recover3 = df_N3.Norm[-1429:-1].to_frame() #len as per the diff\n",
        "recover3[\"Pred\"]= PredJ3\n",
        "Transform_reverssed_J3 = inverse_difference(recover3.Norm, recover3.Pred).to_frame()\n",
        "Transform_reverssed_J3.columns = [\"Pred_Normed\"]\n",
        "#Invert the normalizeation J3\n",
        "Final_J3_Pred = (Transform_reverssed_J3.values* std_J3) + av_J3\n",
        "Transform_reverssed_J3[\"Pred_Final\"] =Final_J3_Pred\n",
        "Sub_Plots2(Transform_reverssed_J3[\"Pred_Final\"], df_3[-1429:-1],\"Pridictions And Orignals For Junction 3\", 2)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-02T07:10:55.628039Z",
          "iopub.execute_input": "2021-09-02T07:10:55.628572Z",
          "iopub.status.idle": "2021-09-02T07:10:56.169375Z",
          "shell.execute_reply.started": "2021-09-02T07:10:55.62853Z",
          "shell.execute_reply": "2021-09-02T07:10:56.16842Z"
        },
        "trusted": true,
        "id": "zEQDKxRO0sfc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The inverse transform on the fourth junction**"
      ],
      "metadata": {
        "id": "hK3ljN3u0sfd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Invert the differenced J4\n",
        "recover4 = df_N4.Norm[-404:-1].to_frame()  #len as per the testset\n",
        "recover4[\"Pred\"]= PredJ4\n",
        "Transform_reverssed_J4 = inverse_difference(recover4.Norm, recover4.Pred).to_frame()\n",
        "Transform_reverssed_J4.columns = [\"Pred_Normed\"]\n",
        "#Invert the normalizeation J4\n",
        "Final_J4_Pred = (Transform_reverssed_J4.values* std_J4) + av_J4\n",
        "Transform_reverssed_J4[\"Pred_Final\"] =Final_J4_Pred\n",
        "Sub_Plots2(Transform_reverssed_J4[\"Pred_Final\"], df_4[-404:-1],\"Pridictions And Orignals For Junction 4\", 3)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-02T07:10:56.170884Z",
          "iopub.execute_input": "2021-09-02T07:10:56.1712Z",
          "iopub.status.idle": "2021-09-02T07:10:56.580166Z",
          "shell.execute_reply.started": "2021-09-02T07:10:56.171168Z",
          "shell.execute_reply": "2021-09-02T07:10:56.579074Z"
        },
        "trusted": true,
        "id": "o55pLBiq0sfd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Summary**\n",
        "\n",
        "*In this project, I trained a GRU Neural network to predicted the traffic on four junctions.\n",
        "I used a normalisation and differencing transform to achieve a stationary timeseries. As the Junctions varry in trends and seasonality, I took diffrent approach for each junction to make it stationary. I applyied the root mean squred error as the evaluation metric for the model. In addition to that I plotted the Predictions alongside the original test values.\n",
        "Take aways from the data analysis:*\n",
        "\n",
        "*The Number of vehicles in Junction one is rising more rapidly compaired to junction two and three. The sparsity of data in juction four bars me from making any conclusion on the same.*\n",
        "\n",
        "*The Junction one's traffic has a stronger weekly seasonality as well as hourly seasonality. Where as other junctions are significantly linear.*\n",
        "\n",
        "**<span style=\"color:#627D78;\"> If you liked this Notebook, please do upvote.</span>**\n",
        "\n",
        "**<span style=\"color:#627D78;\"> Best Wishes!</span>**\n",
        "\n",
        "<a id=\"8\"></a>\n",
        "# <p style=\"background-color:#627D78;font-family:newtimeroman;color:#D5CABD;font-size:150%;text-align:center;border-radius:20px 60px;\">End</p>"
      ],
      "metadata": {
        "id": "JZGUk1OD0sfd"
      }
    }
  ]
}